{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8ad3d1f-2839-4a43-9972-989664a720bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "870f4f1a-79c5-4196-9655-30e213f4b397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_decoder(compressed_img,original_shape):\n",
    "    decompressed = zlib.decompress(compressed_img)\n",
    "    ẑ = np.frombuffer(decompressed, dtype=np.int8)\n",
    "    ẑ = ẑ.reshape(original_shape)\n",
    "    return ẑ\n",
    "    \n",
    "def batch_entropy_decode(compressed_batch,original_size):\n",
    "    z = torch.cat([\n",
    "        torch.tensor(\n",
    "            entropy_decoder(compressed_batch[i], original_size)\n",
    "        ) \n",
    "        for i in range(batch_size)\n",
    "    ])\n",
    "    return z\n",
    "\n",
    "def live_plot(x):\n",
    "    plt.clf()\n",
    "    plt.plot(x)\n",
    "    disp.display(plt.gcf())\n",
    "    disp.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0703f82a-ab6d-4326-880d-45167496a1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FCN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(512, 1024, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(1024, 2048, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv5 = nn.Conv2d(2048, 4096, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv6 = nn.Conv2d(4096, 8192, kernel_size=3, stride=2, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))  # adaptive pooling to 1x1\n",
    "        self.conv7 = nn.Conv2d(8192, 16384, kernel_size=1)  # kernel size 1 to maintain 1x1 size\n",
    "        self.conv8 = nn.Conv2d(16384, 1001, kernel_size=1)  # kernel size 1 to maintain 1x1 size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.pool(x)  # apply adaptive pooling\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = self.conv8(x)  # no activation on the last layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83f44b29-283d-40d8-9a26-df132b5e149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"danjacobellis/imagenet_RDAE_batched_250k\",split='train').with_format(\"torch\")\n",
    "N_classes=1001;\n",
    "net = FCN().to(\"cuda\")\n",
    "parameters = set(p for n, p in net.named_parameters() if not n.endswith(\".quantiles\"))\n",
    "optimizer = optim.Adam(parameters, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "150e9f34-4fa4-47bb-a6b2-7477603b7629",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 32\u001b[0m\n\u001b[1;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     26\u001b[0m torch\u001b[38;5;241m.\u001b[39msave({\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: i,\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: net\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: optimizer\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: loss,\n\u001b[1;32m     31\u001b[0m     }, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier_checkpoint.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m live_plot(\u001b[43mrate\u001b[49m)\n\u001b[1;32m     33\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrate\u001b[39m\u001b[38;5;124m'\u001b[39m,rate)\n\u001b[1;32m     34\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistortion\u001b[39m\u001b[38;5;124m'\u001b[39m,distortion)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rate' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for (i_batch, batch) in enumerate(dataset):\n",
    "        latent_size = batch['latent_size']\n",
    "        batch_size = latent_size[0];\n",
    "        original_size = latent_size.numpy().copy();\n",
    "        original_size[0] = 1;\n",
    "        \n",
    "        compressed_batch = batch['compressed_batch']\n",
    "        z = batch_entropy_decode(compressed_batch,original_size);\n",
    "        z = z.to(\"cuda\").to(torch.float)\n",
    "        \n",
    "        label = batch['label'].to(torch.int64)\n",
    "        y = torch.zeros((batch_size,N_classes,1,1),dtype=torch.int16)\n",
    "        y.scatter_(1, label.view(-1, 1, 1, 1), 1)\n",
    "        y = y.to(\"cuda\").to(torch.float)\n",
    "    \n",
    "        out = net(z)\n",
    "        out = out.squeeze(-1).squeeze(-1)\n",
    "        y = y.squeeze(-1).squeeze(-1)\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        loss = loss_fn(out, y.float()) \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        torch.save({\n",
    "                'epoch': i,\n",
    "                'model_state_dict': net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "            }, f\"classifier_checkpoint.pth\")\n",
    "        live_plot(loss)\n",
    "        \n",
    "        z.detach()\n",
    "        y.detach()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
