{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ba28bd5-c837-4062-8755-1179d584751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "from compressai.entropy_models import EntropyBottleneck\n",
    "from compressai.layers import GDN\n",
    "from compressai.models import CompressionModel\n",
    "from compressai.models.utils import conv, deconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d21d3474-ad4f-42c6-a514-541dfbaad3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(CompressionModel):\n",
    "    def __init__(self, N=128):\n",
    "        super().__init__()\n",
    "        self.entropy_bottleneck = EntropyBottleneck(N)\n",
    "        self.encode = nn.Sequential(\n",
    "            conv(3, N),\n",
    "            GDN(N),\n",
    "            conv(N, N),\n",
    "            GDN(N),\n",
    "            conv(N, N),\n",
    "        )\n",
    "\n",
    "        self.decode = nn.Sequential(\n",
    "            deconv(N, N),\n",
    "            GDN(N, inverse=True),\n",
    "            deconv(N, N),\n",
    "            GDN(N, inverse=True),\n",
    "            deconv(N, 3),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.encode(x)\n",
    "        y_hat, y_likelihoods = self.entropy_bottleneck(y)\n",
    "        x_hat = self.decode(y_hat)\n",
    "        return x_hat, y_likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e350bd51-e6ec-4eed-a4a6-ef2a5174d4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/server/.cache/huggingface/datasets/danjacobellis___parquet/danjacobellis--vimeo90k_triplet-de2b1cb7b7e1797e/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    }
   ],
   "source": [
    "lmbda = 0.01\n",
    "dataset = load_dataset(\"danjacobellis/vimeo90k_triplet\",split='train').with_format(\"torch\")\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30e38c5b-14cd-47b7-8f27-b0eb3d5d1a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = Network().to(\"cuda\")\n",
    "\n",
    "net = Network()\n",
    "net = net.to(\"cuda\")\n",
    "checkpoint = torch.load(\"checkpoint.pth\")\n",
    "net.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "parameters = set(p for n, p in net.named_parameters() if not n.endswith(\".quantiles\"))\n",
    "aux_parameters = set(p for n, p in net.named_parameters() if n.endswith(\".quantiles\"))\n",
    "optimizer = optim.Adam(parameters, lr=1e-4)\n",
    "aux_optimizer = optim.Adam(aux_parameters, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690f5bf6-4a0e-43b1-ab1c-ba9907bdd7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpp = np.array([11])\n",
    "mse = np.array([1])\n",
    "for i,batch in enumerate(dataloader):\n",
    "    optimizer.zero_grad()\n",
    "    aux_optimizer.zero_grad()\n",
    "\n",
    "    x = batch['image'].to(\"cuda\")\n",
    "    x = x.to(torch.float)\n",
    "    x = x/255\n",
    "    x = x - 0.5\n",
    "    x = x.permute(0, 3, 1, 2)\n",
    "    \n",
    "    x_hat, y_likelihoods = net(x)\n",
    "    \n",
    "    # bitrate of the quantized latent\n",
    "    N, _, H, W = x.size()\n",
    "    num_pixels = N * H * W\n",
    "    bpp_loss = torch.log(y_likelihoods).sum() / (-math.log(2) * num_pixels)\n",
    "    bpp = np.append(bpp,bpp_loss.detach().cpu().numpy())\n",
    "    \n",
    "    # mean square error\n",
    "    mse_loss = F.mse_loss(x, x_hat)\n",
    "    mse = np.append(mse,mse_loss.detach().cpu().numpy())\n",
    "    \n",
    "    # final loss term\n",
    "    loss = mse_loss + lmbda * bpp_loss\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    aux_loss = net.aux_loss()\n",
    "    aux_loss.backward()\n",
    "    aux_optimizer.step()\n",
    "\n",
    "    torch.save({\n",
    "            'epoch': i,\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'aux_optimizer_state_dict': aux_optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "        }, f\"checkpoint.pth\")\n",
    "    np.save('mse',mse)\n",
    "    np.save('bpp',bpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f971bf-5d3a-459b-a70b-b794e6443698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
