{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4f99360-2a08-41d5-9ded-b7912486fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from compressai.datasets import ImageFolder\n",
    "from compressai.zoo import image_models\n",
    "from compressai.optimizers import net_aux_optimizer\n",
    "from compressai.losses import RateDistortionLoss\n",
    "from compressai.registry.torch import register_model\n",
    "from compressai.entropy_models import EntropyBottleneck\n",
    "from compressai.layers import GDN\n",
    "from compressai.models.base import CompressionModel\n",
    "from compressai.latent_codecs.base import LatentCodec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "086386a0-34db-48d9-8eed-8c0bb2df2cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RateDistortionAutoEncoder(CompressionModel):\n",
    "    \"\"\"Simple VAE model with arbitrary latent codec.\n",
    "\n",
    "    .. code-block:: none\n",
    "\n",
    "               ┌───┐  y  ┌────┐ y_hat ┌───┐\n",
    "        x ──►──┤g_a├──►──┤ lc ├───►───┤g_s├──►── x_hat\n",
    "               └───┘     └────┘       └───┘\n",
    "    \"\"\"\n",
    "\n",
    "    g_a: nn.Module\n",
    "    g_s: nn.Module\n",
    "    latent_codec: LatentCodec\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.g_a(x)\n",
    "        y_out = self.latent_codec(y)\n",
    "        y_hat = y_out[\"y_hat\"]\n",
    "        x_hat = self.g_s(y_hat)\n",
    "        return {\n",
    "            \"x_hat\": x_hat,\n",
    "            \"likelihoods\": y_out[\"likelihoods\"],\n",
    "        }\n",
    "\n",
    "    def compress(self, x):\n",
    "        y = self.g_a(x)\n",
    "        outputs = self.latent_codec.compress(y)\n",
    "        return outputs\n",
    "\n",
    "    def decompress(self, strings, shape):\n",
    "        y_out = self.latent_codec.decompress(strings, shape)\n",
    "        y_hat = y_out[\"y_hat\"]\n",
    "        x_hat = self.g_s(y_hat).clamp_(0, 1)\n",
    "        return {\n",
    "            \"x_hat\": x_hat,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b33133bc-1595-428c-b264-e7ab306cbe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model='bmshj2018-factorized'\n",
    "dataset='/home/server/datasets/example'\n",
    "epochs=100\n",
    "learning_rate=0.0001\n",
    "num_workers=1\n",
    "lmbda=0.01\n",
    "batch_size=16\n",
    "test_batch_size=64\n",
    "aux_learning_rate=0.001\n",
    "patch_size=(256, 256)\n",
    "cuda=True\n",
    "save=True\n",
    "seed=0\n",
    "clip_max_norm=1.0\n",
    "checkpoint=None\n",
    "# checkpoint = 'checkpoint_best_loss.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "948163ad-5683-4762-9c25-a1efeb30dfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_optimizers(net):\n",
    "    \"\"\"Separate parameters for the main optimizer and the auxiliary optimizer.\n",
    "    Return two optimizers\"\"\"\n",
    "    conf = {\n",
    "        \"net\": {\"type\": \"Adam\", \"lr\": learning_rate},\n",
    "        \"aux\": {\"type\": \"Adam\", \"lr\": aux_learning_rate},\n",
    "    }\n",
    "    optimizer = net_aux_optimizer(net, conf)\n",
    "    return optimizer[\"net\"], optimizer[\"aux\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee7dec53-a0d3-4614-afac-8c5ef9efa63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model, criterion, train_dataloader, optimizer, aux_optimizer, epoch, clip_max_norm\n",
    "):\n",
    "    model.train()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    for i, d in enumerate(train_dataloader):\n",
    "        d = d.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        aux_optimizer.zero_grad()\n",
    "\n",
    "        out_net = model(d)\n",
    "\n",
    "        out_criterion = criterion(out_net, d)\n",
    "        out_criterion[\"loss\"].backward()\n",
    "        if clip_max_norm > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_max_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "        aux_loss = model.aux_loss()\n",
    "        aux_loss.backward()\n",
    "        aux_optimizer.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\n",
    "                f\"Train epoch {epoch}: [\"\n",
    "                f\"{i*len(d)}/{len(train_dataloader.dataset)}\"\n",
    "                f\" ({100. * i / len(train_dataloader):.0f}%)]\"\n",
    "                f'\\tLoss: {out_criterion[\"loss\"].item():.3f} |'\n",
    "                f'\\tMSE loss: {out_criterion[\"mse_loss\"].item():.3f} |'\n",
    "                f'\\tBpp loss: {out_criterion[\"bpp_loss\"].item():.2f} |'\n",
    "                f\"\\tAux loss: {aux_loss.item():.2f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b75f414e-0002-49c2-b370-247a4b646c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(epoch, test_dataloader, model, criterion):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    loss = AverageMeter()\n",
    "    bpp_loss = AverageMeter()\n",
    "    mse_loss = AverageMeter()\n",
    "    aux_loss = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in test_dataloader:\n",
    "            d = d.to(device)\n",
    "            out_net = model(d)\n",
    "            out_criterion = criterion(out_net, d)\n",
    "\n",
    "            aux_loss.update(model.aux_loss())\n",
    "            bpp_loss.update(out_criterion[\"bpp_loss\"])\n",
    "            loss.update(out_criterion[\"loss\"])\n",
    "            mse_loss.update(out_criterion[\"mse_loss\"])\n",
    "\n",
    "    print(\n",
    "        f\"Test epoch {epoch}: Average losses:\"\n",
    "        f\"\\tLoss: {loss.avg:.3f} |\"\n",
    "        f\"\\tMSE loss: {mse_loss.avg:.3f} |\"\n",
    "        f\"\\tBpp loss: {bpp_loss.avg:.2f} |\"\n",
    "        f\"\\tAux loss: {aux_loss.avg:.2f}\\n\"\n",
    "    )\n",
    "\n",
    "    return loss.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e5315e0-20e2-46e1-bf6f-7dc6170ca724",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"Compute running average.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5972b3b-5374-4d0a-8388-1774f8b06a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename=\"checkpoint.pth.tar\"):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, \"checkpoint_best_loss.pth.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97c19ca3-9318-4837-b59c-754911dc26a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m net \u001b[38;5;241m=\u001b[39m RateDistortionAutoEncoder()\n\u001b[1;32m     33\u001b[0m net \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 34\u001b[0m optimizer, aux_optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mconfigure_optimizers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m lr_scheduler \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(optimizer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m criterion \u001b[38;5;241m=\u001b[39m RateDistortionLoss(lmbda\u001b[38;5;241m=\u001b[39mlmbda)\n",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m, in \u001b[0;36mconfigure_optimizers\u001b[0;34m(net)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Separate parameters for the main optimizer and the auxiliary optimizer.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mReturn two optimizers\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m conf \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnet\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: learning_rate},\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maux\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: aux_learning_rate},\n\u001b[1;32m      7\u001b[0m }\n\u001b[0;32m----> 8\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mnet_aux_optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m optimizer[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnet\u001b[39m\u001b[38;5;124m\"\u001b[39m], optimizer[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maux\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/compressai/optimizers/net_aux.py:72\u001b[0m, in \u001b[0;36mnet_aux_optimizer\u001b[0;34m(net, conf)\u001b[0m\n\u001b[1;32m     69\u001b[0m     params \u001b[38;5;241m=\u001b[39m (params_dict[name] \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(parameters[key]))\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m OPTIMIZERS[conf[key][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m]](params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 72\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m {key: make_optimizer(key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnet\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maux\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(Dict[\u001b[38;5;28mstr\u001b[39m, optim\u001b[38;5;241m.\u001b[39mOptimizer], optimizer)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/compressai/optimizers/net_aux.py:72\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     69\u001b[0m     params \u001b[38;5;241m=\u001b[39m (params_dict[name] \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(parameters[key]))\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m OPTIMIZERS[conf[key][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m]](params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 72\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m {key: \u001b[43mmake_optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnet\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maux\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(Dict[\u001b[38;5;28mstr\u001b[39m, optim\u001b[38;5;241m.\u001b[39mOptimizer], optimizer)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/compressai/optimizers/net_aux.py:70\u001b[0m, in \u001b[0;36mnet_aux_optimizer.<locals>.make_optimizer\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     69\u001b[0m params \u001b[38;5;241m=\u001b[39m (params_dict[name] \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(parameters[key]))\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mOPTIMIZERS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:33\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weight_decay value: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(weight_decay))\n\u001b[1;32m     29\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(lr\u001b[38;5;241m=\u001b[39mlr, betas\u001b[38;5;241m=\u001b[39mbetas, eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m     30\u001b[0m                 weight_decay\u001b[38;5;241m=\u001b[39mweight_decay, amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m     31\u001b[0m                 maximize\u001b[38;5;241m=\u001b[39mmaximize, foreach\u001b[38;5;241m=\u001b[39mforeach, capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[1;32m     32\u001b[0m                 differentiable\u001b[38;5;241m=\u001b[39mdifferentiable, fused\u001b[38;5;241m=\u001b[39mfused)\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:187\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    185\u001b[0m param_groups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(params)\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(param_groups) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer got an empty parameter list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(param_groups[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    189\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: param_groups}]\n",
      "\u001b[0;31mValueError\u001b[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "train_transforms = transforms.Compose(\n",
    "    [transforms.RandomCrop(patch_size), transforms.ToTensor()]\n",
    ")\n",
    "test_transforms = transforms.Compose(\n",
    "    [transforms.CenterCrop(patch_size), transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "train_dataset = ImageFolder(dataset, split=\"train\", transform=train_transforms)\n",
    "test_dataset = ImageFolder(dataset, split=\"test\", transform=test_transforms)\n",
    "\n",
    "device = \"cuda\" if cuda and torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True,\n",
    "    pin_memory=(device == \"cuda\"),\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False,\n",
    "    pin_memory=(device == \"cuda\"),\n",
    ")\n",
    "\n",
    "# net = image_models[model](quality=3)\n",
    "net = RateDistortionAutoEncoder()\n",
    "net = net.to(device)\n",
    "optimizer, aux_optimizer = configure_optimizers(net)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\")\n",
    "criterion = RateDistortionLoss(lmbda=lmbda)\n",
    "last_epoch = 0\n",
    "\n",
    "if checkpoint:  # load from previous checkpoint\n",
    "    print(\"Loading\", checkpoint)\n",
    "    checkpoint = torch.load(checkpoint, map_location=device)\n",
    "    last_epoch = checkpoint[\"epoch\"] + 1\n",
    "    net.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    aux_optimizer.load_state_dict(checkpoint[\"aux_optimizer\"])\n",
    "    lr_scheduler.load_state_dict(checkpoint[\"lr_scheduler\"])\n",
    "\n",
    "best_loss = float(\"inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d67201b-6c5d-4ed4-9fe9-4dd3aa8ad175",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(last_epoch, epochs):\n",
    "    print(f\"Learning rate: {optimizer.param_groups[0]['lr']}\")\n",
    "    train_one_epoch(\n",
    "        net,\n",
    "        criterion,\n",
    "        train_dataloader,\n",
    "        optimizer,\n",
    "        aux_optimizer,\n",
    "        epoch,\n",
    "        clip_max_norm,\n",
    "    )\n",
    "    loss = test_epoch(epoch, test_dataloader, net, criterion)\n",
    "    lr_scheduler.step(loss)\n",
    "\n",
    "    is_best = loss < best_loss\n",
    "    best_loss = min(loss, best_loss)\n",
    "\n",
    "    if save:\n",
    "        save_checkpoint(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"state_dict\": net.state_dict(),\n",
    "                \"loss\": loss,\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "                \"aux_optimizer\": aux_optimizer.state_dict(),\n",
    "                \"lr_scheduler\": lr_scheduler.state_dict(),\n",
    "            },\n",
    "            is_best,\n",
    "        )\n",
    "net.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e06f7d3-d06e-40fd-939b-891962a5472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as Image\n",
    "import torchvision\n",
    "from diffusers.utils import pt_to_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d90774-5878-4be1-a173-8359e0704144",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50accbe-9d43-4d4e-a20b-1714b26372c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c20610b-639f-4437-be19-68d6c51c87fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('kodim05.png')\n",
    "# img = img.crop((0,0,256,256))\n",
    "def pil_to_pt(img):\n",
    "    t = transforms.functional.pil_to_tensor(img)\n",
    "    t = t.to(torch.float)\n",
    "    t = t/255\n",
    "    t = t.unsqueeze(0)\n",
    "    return t\n",
    "t = pil_to_pt(img)\n",
    "print(img.width)\n",
    "print(img.height)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc8f58f-30e2-4bca-891e-0aa62d94c95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = net.g_a(t.to(\"cuda\"))\n",
    "z = z.round()\n",
    "y = net.g_s(z)\n",
    "x = y.detach()\n",
    "pt_to_pil(2*x-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2b5183-d1a4-4535-ae18-a4866131a56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
